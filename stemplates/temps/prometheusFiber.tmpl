package observe

import (
	"log"
	"math/rand"
	"net/http"
	"time"

	"{{.ProjectName}}/configs"
	"github.com/gofiber/fiber/v3"
	"github.com/prometheus/client_golang/prometheus"
	"github.com/prometheus/client_golang/prometheus/promhttp"
	"github.com/shirou/gopsutil/cpu"
	"github.com/shirou/gopsutil/mem"
)


//
// ================= CONFIG =================
//

// 1 = 100%, 10 = 10%, 100 = 1%
const httpSampleRate = 10

//
// ================= METRICS =================
//

var (
	cpuUsage = prometheus.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "cpu_usage_percentage",
			Help: "CPU usage percentage",
		},
		[]string{"service"},
	)

	memUsage = prometheus.NewGaugeVec(
		prometheus.GaugeOpts{
			Name: "memory_usage_percentage",
			Help: "Memory usage percentage",
		},
		[]string{"service"},
	)

	httpDuration = prometheus.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "http_request_duration_seconds",
			Help:    "HTTP request duration",
			Buckets: prometheus.DefBuckets,
		},
		[]string{"method", "route", "status", "service"},
	)
)

//
// ================= INIT =================
//

func InitPromDetail(reg *prometheus.Registry, cfg *configs.EnvConfig) {
	reg.MustRegister(cpuUsage, memUsage, httpDuration)
	go collectSystemMetrics(cfg)
}

// var httpDuration *prometheus.HistogramVec

func InitProm(reg *prometheus.Registry, cfg *configs.EnvConfig) {
	// serviceName := cfg.Get("APP_NAME")

	httpDuration = prometheus.NewHistogramVec(
		prometheus.HistogramOpts{
			Name:    "http_request_duration_seconds",
			Buckets: []float64{.001, .005, .01, .025, .05, .1}, // Pruned buckets = faster processing
		},
		[]string{"method", "route", "status", "service"},
	)

	reg.MustRegister(httpDuration)
}

//
// ================= SYSTEM METRICS =================
//

func collectSystemMetrics(cfg *configs.EnvConfig) {
	service := cfg.Get("APP_NAME")

	for {
		// CPU
		if cpuPercent, err := cpu.Percent(0, false); err == nil && len(cpuPercent) > 0 {
			cpuUsage.WithLabelValues(service).Set(cpuPercent[0])
		}

		// Memory
		if v, err := mem.VirtualMemory(); err == nil {
			memUsage.WithLabelValues(service).Set(
				float64(v.Used) / float64(v.Total) * 100,
			)
		}

		time.Sleep(5 * time.Second)
	}
}

//
// ================= HTTP METRICS =================
//

// Pre-allocated status strings (NO fmt)
var statusStrings = map[int]string{
	200: "200", 201: "201", 204: "204",
	400: "400", 401: "401", 403: "403", 404: "404",
	500: "500", 502: "502",
}

func status(code int) string {
	if s, ok := statusStrings[code]; ok {
		return s
	}
	return "500"
}

func HTTPMetricsMiddleware(cfg *configs.EnvConfig) fiber.Handler {
	service := cfg.Get("APP_NAME")

	return func(c fiber.Ctx) error {
		start := time.Now()
		err := c.Next()

		// Cheap sampling
		if httpSampleRate > 1 && rand.Intn(httpSampleRate) != 0 {
			return err
		}

		route := c.Route().Path
		if route == "" {
			route = "unknown"
		}

		httpDuration.WithLabelValues(
			c.Method(),
			route,
			status(c.Response().StatusCode()),
			service,
		).Observe(time.Since(start).Seconds())

		return err
	}
}

func HTTPMetricsMiddlewareOp(cfg *configs.EnvConfig) fiber.Handler {
	service := cfg.Get("APP_NAME")
	return func(c fiber.Ctx) error {
		start := time.Now()
		err := c.Next()

		// Sample 1 out of 100 requests to reach 250k RPS
		// At 250k RPS, 1% sampling still gives 2,500 data points per second!
		if rand.Uint32()%100 != 0 {
			return err
		}

		// Use pre-allocated status codes
		codeStr := status(c.Response().StatusCode())

		httpDuration.WithLabelValues(
			c.Method(),
			c.Route().Path,
			codeStr,
			service,
		).Observe(time.Since(start).Seconds())

		return err
	}
}

//
// ================= METRICS SERVER =================
//

func StartMetricsServer(addr string, reg *prometheus.Registry) {
	go func() {
		log.Println("[metrics] listening on", addr)
		http.Handle("/metrics", promhttp.HandlerFor(reg, promhttp.HandlerOpts{}))
		if err := http.ListenAndServe(addr, nil); err != nil {
			log.Fatal(err)
		}
	}()
}

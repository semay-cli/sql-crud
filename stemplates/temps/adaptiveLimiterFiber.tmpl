package manager

import (
	"sync"
	"sync/atomic"
	"time"

	"github.com/gofiber/fiber/v3"
)

type AdaptiveLimiter struct {
	limit        int64
	minLimit     int64
	maxLimit     int64
	inFlight     int64
	moving       bool
	targetP99    float64 // Use float64 for nanoseconds calculation
	requestCount int64
	smoothedLat  float64 // EWMA state
	alpha        float64 // Smoothing factor (0.1 to 0.3 is typical)
	mu           sync.RWMutex
}

func NewAdaptiveLimiter(min, max int64, targetP99 time.Duration, moving bool) *AdaptiveLimiter {
	return &AdaptiveLimiter{
		limit:       min + (max-min)/2,
		minLimit:    min,
		maxLimit:    max,
		targetP99:   float64(targetP99.Nanoseconds()),
		alpha:       0.2, // 20% weight to new data, 80% to history
		smoothedLat: float64(targetP99.Nanoseconds()),
		moving:      moving,
	}
}

func (l *AdaptiveLimiter) Handle(c fiber.Ctx) error {
	// 1. Check Capacity (Atomic Increment)
	currentInFlight := atomic.AddInt64(&l.inFlight, 1)
	defer atomic.AddInt64(&l.inFlight, -1)

	limit := atomic.LoadInt64(&l.limit)

	// If we are over capacity, shed load immediately
	if currentInFlight > limit {
		return c.Status(fiber.StatusTooManyRequests).JSON(fiber.Map{
			"error":       "server capacity reached",
			"retry_after": "1s",
		})
	}

	// 2. Measure Execution
	start := time.Now()
	err := c.Next()
	duration := time.Since(start)

	// 3. Adaptive Adjustment (Every 500 requests to minimize overhead)
	if atomic.AddInt64(&l.requestCount, 1)%500 == 0 {
		if l.moving {
			l.adjustmoving(duration)

		} else {
			l.adjust(duration)
		}
	}

	return err
}

// simple
func (l *AdaptiveLimiter) adjust(lastLatency time.Duration) {
	currLimit := atomic.LoadInt64(&l.limit)

	// Additive Increase: If latency is good, try to handle more
	if float64(lastLatency) <= l.targetP99 && currLimit < l.maxLimit {
		atomic.AddInt64(&l.limit, 1)
	}
	// Multiplicative/Aggressive Decrease: If latency is bad, shrink the pool
	if float64(lastLatency) > (l.targetP99*12/10) && currLimit > l.minLimit {
		// Reduce by 10% or at least 1 for quicker recovery from congestion
		decrease := currLimit / 10
		if decrease < 1 {
			decrease = 1
		}
		atomic.AddInt64(&l.limit, -decrease)
	}
}

// moving average
func (l *AdaptiveLimiter) adjustmoving(lastLatency time.Duration) {
	newLat := float64(lastLatency.Nanoseconds())

	l.mu.Lock()
	// alpha 0.2 provides a good balance between stability and reaction speed
	l.smoothedLat = (0.2 * newLat) + (0.8 * l.smoothedLat)
	currentMovingAvg := l.smoothedLat
	l.mu.Unlock()

	currLimit := atomic.LoadInt64(&l.limit)

	// 1. Growth Phase (Additive Increase)
	if currentMovingAvg <= l.targetP99 && currLimit < l.maxLimit {
		atomic.AddInt64(&l.limit, 1)

	} else if currentMovingAvg > (l.targetP99*1.25) && currLimit > l.minLimit {
		// 2. Panic Phase (Multiplicative Decrease)
		// Using 1.25x target as the "danger zone"
		decrease := currLimit / 5 // More aggressive (20%) drop for non-cached routes
		if decrease < 1 {
			decrease = 1
		}
		atomic.AddInt64(&l.limit, -decrease)

	}
}
